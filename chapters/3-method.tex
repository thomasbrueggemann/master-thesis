\section{Implementation and Evaluation of an Automated Information Privacy Risk Assessment Tool}

% Implementation of an Automated Information Privacy Risk Assessment Tool
\subsection{Implementation of an Automated Information Privacy Risk Assessment Tool}

The implementation of an \aiprat is structured in three phases.
In the first phase, Android APK files need to be downloaded to acquire the foundation of a static code analysis: the source code.
While APK files are binary representations of source code, it is necessary, in a second phase, to decompile to binary code back into actual source files.
The third phase is the analysis phase, where the information privacy risk assessment takes place.

Figure \ref{fig:implementationPhases} shows the implementation phases over time including the tools used within each phase. 
The tools will be described in greater detail within the following chapters.

\begin{figure}[h]
	\caption{Diagram of implementation phases over time.}
	\centering
	\includegraphics[keepaspectratio=true,width=400pt]{figures/ImplementationFlow.png}
	\label{fig:implementationPhases}
\end{figure}

% Download Phase
\subsubsection{Download Phase}

The download phase is the first of the three implementation phases and comprises the acquisition of Android APK files. 
The APK files hold the necessary Java source code that we will perform the \sca on.
Since this thesis emphases on Android mHealth apps, we used the repository database of \cite{Xu2015} as our main app data source.\footnote{This paragraph follows \cite{Xu2015}.}
\cite{Xu2015} list mHealth apps from the Apple AppStore and Android PlayStore and update their repository quarterly by scraping the app stores.
The list contains information for example on the app's id, category in the app stores, description, email address of the developer, price and the user rating of the app.

We used the repository database to loop over the available mHealth app listings and filtered out the apps that were available for free, indicated by a price of \$0.00.
As soon as the package name of an app is gathered, the download of the \acs{APK} file can begin. 
While there is no official source to download \acs{APK} files for Android apps, a multitude of websites exist that host copies of \acs{APK} files to download for free.
Unfortunately, all of these websites implement mechanisms that make it impossible to browse and download the APK files programatically within a download script.
Instead, we used a open source Python implementation of an undocumented Google PlayStore \acs{API}.\footnote{https://github.com/egirault/googleplay-api, visited 05/12/2016} 
The undocumented part of the Google API allows users to download APK files 
Even though the project has not been maintained for four years, the software is still in working order.
The Python script authenticates to the Google API via the hardware ID of an Android smartphone or tablet and pretends to request data from this smartphone or tablet, even though the requests are sent from a desktop computer.
We used a real Android tablet to detect its hardware ID and authenticate the Google API requests with this hardware ID.
The main issue that has to be taken care of during the download phase is not to run into Google API limitations. 
Google allows an API user to only request a certain amount requests per time unit. 
After this limit is exceeded, the requests will just return a HTTP error code and no APK file will be downloaded.
In order to work around this circumstance, we ran our download script multiple times, always until the Google API returns error codes. 
We then waited a couple of hours and tried the download script again, which would pick up the download process where it had stopped on the last run.

% Decompilation Phase
\subsubsection{Decompilation Phase}

In order to decompile the amount of APK files available, it is necessary to automate the process. 
The automation script\footnote{https://github.com/thomasbrueggemann/AIPRAT/blob/master/decompile/decompile.sh} uses a chain of tools to gather access to the source code files from an APK file.
The tools used to decompile the APK files follow closely the tools described and used by \cite{Enck2011}.\footnote{See \cite{Enck2011}, p. 5.}

In a first step, we use the tool \textit{dex2jar} to extract the \acs{JAR} file from the APK file.
The JAR file contains the java bytecode representations of the app which is just one part of the contents of an \acs{APK} file.
The next step is to extract resource files, such as the \textit{Android Manifest} file from the APK file.
The \textit{Android Manifest} contains meta information about the app in a structured XML format.\footnote{This and the next sentence follow \cite{xu2013}, p. 7.}
The meta information include the package name of the app, the permissions the app requests, e.g. camera usage, internet access or geolocation usage.
The \textit{Android Manifest} file is therefore an important indicator for high level activities within the given app.
In order to extract the \textit{Android Manifest} file from the APK file along with other resources such as images, icons, xml files or other files used within the app, we use the \textit{apktool}\footnote{http://ibotpeaches.github.io/Apktool/}.
\textit{apktool} is a frequently updated Android reverse engineering tool that is used to extract resources from APK files.
At the core of the decompilation process is the usage of \textit{fernflower}\footnote{https://github.com/fesh0r/fernflower}.
\textit{fernflower} is the recommended java decompiler by \cite{Enck2011}. 
They used the tool to decompile a test sample of apps and gained a significantly higher code recovery rate than by using other decompiling tools.\footnote{See \cite{Enck2011}, p. 6.}
An obstacle in decompiling java source code is obfuscation. 
Java developers can make use of a security feature called obfuscation that aims at hiding away the logic of java classes by renaming classes, variables and method names and disassembling the code into pieces that are difficult to read for an human interpreter.
The idea is to make it more difficult to retrieve and make sense of the original source code by decompiling the byte code.
\textit{fernflower} uses a renaming approach by assigning every obfuscated class with a new naming pattern. 
Member variables and methods will be automatically renamed and therefore provide an easier and more unique way of reading the source code.
Optionally the decompilation process can use an automatic code formatting tool called \textit{astyle}\footnote{http://astyle.sourceforge.net/} to format the source code.
This helps humans to read the source code files more easily, since the formatting and indentation of all source code files is identical and therefore very structured.
Formatting the source code will help in the evaluation phase of this thesis to support the manual inspection the source code for \ipr by human researchers.

The expected result of the decompilation phase is a directory named after the package name of a given app that contains the resource files, including the \textit{Android Manifest} and the decompiled source code of the app.

% Static Code Analysis Phase
\subsubsection{Static Code Analysis Phase}

The \sca phase is the main analysis phase of the thesis and uses the output of the previous decompilation phase to perform the static code analysis.
The \sca tool is implemented as a Java software project, since the used analysis libraries are implemented in Java and Android source code is written in Java too.
The output of the \sca Java project is an executable Java archive file called \textit{AIPRAT.jar} that can be executed in the command line terminal.
In order for \textit{AIPRAT.jar} to perform the \sca on APK files, two preparation steps are required.

The first preparation step is to run an Android data flow analysis tool over the APK files that extract potential data flows.
The data flow analysis is achieved with an open source tool called \textit{FlowDroid}, introduced by \cite{Arzt2014}.\footnote{See \cite{Arzt2014}, p. 259-269.}
\textit{FlowDroid} extends the Java optimization framework \textit{Soot}, which was already used by \cite{Enck2011} for post-decompilation optimization tasks.\footnote{See \cite{Enck2011}, p. 5.}
The data flow is analysed by scanning an intermediate byte code format provided by \textit{Soot} for so called 'sources' and 'sinks'.\footnote{See \cite{Arzt2014}, p. 264.}
A source is the origin of a data flow, e.g. the user input of data via a textfield and a sink is the destination that data flows.
An example for a sink is a HTTP internet connection or a local log file.
\textit{FlowDroid} is also able to emulate Android lifecycle entry points.
While a regular Java program has a single entry point to start the application from, the \textit{main()} function, Android apps provide multiple entry points.
The entry points of an Android app are determined by the states an app can be in. 
It can e.g. return from being in the background, do a fresh start and return from being offline.
All these entry points are being emulated by \textit{FlowDroid} into a single \textit{main()} function call.
The output of the data flow analysis is one XML file per analysed APK file that contains a list of sinks and the coherent sources of data flows to that sink.
The XML file will be parsed by the main \sca tool later on and the sink and source methods will be interpreted in the context of information privacy risks.

The machine learning text classifiers will be trained within the second preparation step.
During the \sca phase of this study, we will be making great use of the naive Bayes classifier.
A machine learning text-classifier classifies text segments into distinct categories. 
The categories are predefined in the training phase of the classifier, since every trained text segment is assigned with a training category.
These training categories are the categories the classifier can assign to new, previously unseen, text segments.
The incisive feature of a Bayes classifier is the fact, that it chooses to classify a category to a new segment of text by picking the most probable category.\footnote{For this and the following two sentences see \cite{Rish2001}, p. 41.}
A \nbc furthermore assumes that all categories are distinct and independent of each other. 
Even though this might not always be the case in a real life usage scenario, the \nbc still performs well enough for a wide range of use cases.

In the case of the \sca in this study, we will be using the \nbc to classify URLs into categories.
The categories that URLs can belong to, in the context of this study, are: advertisement, delivery services, government, instant-messaging, (data-) aggregation services, search engines and social networks.
While the set of categories might not complete in terms of all possible and available categories, it is sufficient for the classification of URLs within this \sca to classify into the mentioned category-set.
In oder for the \nbc to classify text into categories we trained a \nbc implementation with meta-information about URLs from the previously mentioned categories.
First, it was necessary to collect URLs for the categories to train the \nbc and we used a collection of \acs{URL}s from \textit{URLBlacklist.com}\footnote{http://www.urlblacklist.com/?sec=download, visited 05/30/2016}.
\textit{URLBlacklist.com} provides URL lists for the categories advertisement, government, instant-messaging, search engines and social networks.
\textit{programmableweb.com} catalogues API descriptions including the service providers' URL.
We developed a program to automatically download and store the API directory for the two remaining categories, from \textit{programmableweb.com}.

Next, to acquire meta-information for all the URLs, we implement a downloader for the HTML source-code of all URLs and store the 'description' HTML-meta tag content in a file.
The 'description' meta-tag contains a small amount of text, provided by the website owner, that describes the content or function of the website topic.
We use this 'description' meta-information to train the classifier with the associated categories.\newline

As soon as the preparation steps are finished, the main \sca tool is ready to perform the \ipr analysis.
We call the main \sca tool '\textit{AIPRAT}', short for \aiprat from here on.
The fundamental concept of \AIPRAT is to iterate over all available apps and apply a set of analysis operations, called 'strategies', to the source code of these apps.
A strategy tries to identify \iprfs by applying algorithms, e.g. feature extraction or text search, to parts of the app source code.
There are two types of strategies in \AIPRAT, generic and specific strategies.
Generic strategies are strategies that contain algorithms that are configurable and usable by other specific strategies.
An example for a generic strategy is the Java-class \textit{analyze.src.strategies.ExistanceStrategy}. 
The \textit{ExistanceStrategy} is able to scan through all source code files of an app and search for a set of words.
If one or more of the source code files contains one or more of the search words, the \textit{ExistanceStrategy} returns a set of source code snippets that contain the lines of code containing the search words.
In total \AIPRAT contains four generic strategies in the Java-package \textit{analyze.src.strategies}: DataFlowStrategy, ExistanceStrategy, PermissionStrategy and UrlCategoryStrategy.
The DataFlowStrategy parses the pre-extracted dataflow \acs{XML} from the \textit{FlowDroid} preparation phase and allows iterating over all identified dataflow sources and sinks.
Thereby, the DataFlowStrategy allows to pass parameters along that filter the sources and sinks for certain search words and provide feedback if the search words were found within sources and sinks.

A specific strategy, on the other hand, targets the exploration of an \ipp directly and contains the \ipp hierarchy identifier, introduced by \textcite{Dehling2016}, in its Java-classname.\footnote{See \cite{Dehling2016}, p. 6.}
The Java-class \textit{analyze.src.strategies.CI213\textunderscore Strategy} contains a search pattern for the \ipp with the hierarchy identifier CI213, which refers to the \ipp Content (C) $\rightarrow$ InformationCollectionContent (I) $\rightarrow$ InformationCollectionSensorContent (2) $\rightarrow$ EnvironmentSensorContent (1) $\rightarrow$ MicrophoneContent (3).
Therefore a specific strategy may contain a combination of one or many generic strategies to try to identify the risk the associated \ipp is posing through static code analysis.
In the example of the specific strategy \textit{analyze.src.strategies.CI213\textunderscore Strategy}, the class extends the generic strategy class \textit{analyze.src.strategies.ExistanceStrategy} and sets the search parameters of the \textit{ExistanceStrategy} to 'MediaRecorder.setAudioSource(' and 'MediaRecorder.AudioSource.MIC'.
The \textit{CI213\textunderscore Strategy} class scans via the parent-class \textit{ExistanceStrategy} all of the source code files off the app for source code that uses the Android microphone \acs{API}.


\subsection{Evaluation of an Automated Information Privacy Risk Assessment Tool}