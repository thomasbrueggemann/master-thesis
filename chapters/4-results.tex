\section{Feasibility of Automated Information Privacy Risk Assessment}

Within the following chapter we want to express the results of the implementation and evaluation phase and assess to what degree the automation of information privacy risk assessment is feasible.
We will also present the results on how well the \aiprat performs in comparison to human researchers.

\subsection{The Automated Information Privacy Risk Assessment of Free Android mHealth Apps}

The results of the download, decompilation and \sca phase will be outlined in the following sections.

\subsubsection{Download Phase}

The original dataset from the \cite{Xu2015} repository of app store listings contains 5,379 app entries from the Google PlayStore in the category 'Medical' and 'Health and Fitness'.
From this original dataset we extracted the 3,180 free apps for further inspection.
It was possible to download 2,250 app APK files via the undocumented Google API.
The remaining 930 APK files either returned a Google authentication error or were not available on the Google PlayStore anymore.

Downloading the 2,250 APK files took multiple download-runs over the whole dataset, since the Google API only allows a certain amount of download requests per time unit.
The number of allowed download requests varied throughout the download phase and could not be detected exactly.
Various tests downloading APK files automatically via websites like apkpure.com\footnote{\url{https://web.archive.org/web/20160528165049/https://apkpure.com/}, visited 06/05/2016} or apk-dl.com\footnote{\url{https://web.archive.org/web/20160518104842/https://apk-dl.com}, visited 06/05/2016} failed due to those websites effectively blocking automated non-browser traffic.
The download of the 2,250 APK files took 11 days in total and 18 restart attempts of the download script.

\subsubsection{Decompilation Phase}

From the downloaded 2,250 APK files, 355 were decompiled. 
The reason that only 15\% of the 2,250 APK files were decompiled is the time that was available to write this thesis.
The decompilation time varied from 4 minutes to 16 minutes, based on the amount and complexity of the source files of the app.
The 355 APK files that were decompiles were selected in order of their file size.
An app with a lower file size was chosen over an app with a larger file size.
The reason for this is the restriction of \textit{FlowDroid} to only analyze apps that are under a certain file size and complexity,due to \textit{FlowDroids'} internal memory management.

During the decompilation of the APK files from smallest file size to largest, the decompilation failed to finish in 24 cases.
Reasons for decompilation failure are heavily obfuscated source code, that forced the decompiler to abort the process and memory exceptions.
Memory exceptions appear if the source code files of the currently decompiled app exceed the size of the available main memory of the computer that performs the decompilation.
This memory exceeding happens due to the fact that \textit{fernflower} keeps all source code file representations in main memory (including the Java virtual machine overhead) and therefore consumes a lot of memory.

\subsubsection{Static Code Analysis Phase}

The \sca phase went through three revisions. 
The first revision was based on the idea that the \textit{FlowDroid} \acs{API} can be used within the \AIPRAT tool itself as an external library.
This attempt failed due to the fact that \textit{FlowDroid} uses significant amounts of main memory.
In case \textit{FlowDroid} ran out of memory, for apps with a larger or more complex source code structure, the operating system buffers the main memory to the hard disk which causes the running application to be slow.
Further analysis was therefore impossible and the \textit{FlowDroid} analysis would take infeasible amounts of time.

The second revision of the \sca phase was to outsource the \textit{FlowDroid} analysis into a separate application that precomputes the dataflows of any app in our dataset and stores the dataflow results in an \acs{XML} file format.
The idea behind this revision was, to be able to run the \textit{FlowDroid} dataflow analysis on high performance virtual machines in the Amazon Cloud.
We used a \textit{m4.4xlarge} instance\footnote{\url{https://web.archive.org/web/20160415154133/http://aws.amazon.com/ec2/instance-types/}, visited 07/19/16.}, which is equipped with 64 gigabytes of main memory.
But even considering the great number of main memory available on the Amazon Cloud virtual machine, \textit{FLowDroid} was reluctant to compute the dataflow for certain apps on the dataset.
The second downside of precomputing the dataflow analysis, is the fact that reading in the pre-computed dataflow analysis from a XML file does not provide the live-context information of using the \textit{FlowDroid} API directly within the code.
The \textit{FlowDroid} objects that represent methods and relationships between methods are to complex to be fully stored within XML files.
Therefore analysis of the callgraph of methods is very limited with this revisions' approach.

The last and final revision of the \sca phase discovered a part of the \textit{FlowDroid} API that only computes the call graphs of apps with a limited subset of all the features that \textit{FlowDroid} yields.
The limited subset redeemed to be completely sufficient for the analysis purposes of this thesis.
While large and complex apps still take up the main memory quickly, the threshold of APK file size seems to have changed to rather larger files for this approach.
Therefore, we decided to conduct the \sca on the 15\% of the apps with the smallest file size, from the original dataset.

The \sca tool was able to finish the analysis on 317 apps from the decompiled 355.
The reason for the roughly 10\% loss of apps from the decompilation to the \sca phase is mainly due to error in the generation of the callgraph by \textit{FlowDroid}.
As mentioned before, apps could be to too large in file size for \textit{FlowDroid} to fit into main memory, and the \sca would skip to the next app.

Table \ref{table:strategyResults} shows an overview of all implemented strategies to identify information privacy risks within an app and the number of found appearances throughout the \sca phase.
While 14 of the 44 strategies did not find any results within the analysis phase, 30 did.
In this case of an \ipr analysis, a non-found of a risk by a strategy is not necessarily a negative aspect.
Especially the strategies for \textit{CH36} SharingWithDeliveryContent and \textit{CI344} IdeologicalContent do not particularly apply to the context of \mH apps and their information privacy risks.
On average, 4.86 potential information privacy risk were found per app by the implemented strategies.

\begin{table}[]
\centering
\begin{tabular}{|p{8cm}|p{6cm}|}
\hline
\textbf{Information privacy practice hierarchy identifiers}  & \textbf{Number of 'Found' Appearances in Results} \\ \hline
CH34, CH36, CH37, CH38, CH43, CH45, CI213, CI222, CI223, CI321, CI322, CI344, CI345, CI346  & 0   \\ \hline
CI343 & 1   \\ \hline
CH42, CI231  & 2   \\ \hline
CI214 & 3   \\ \hline
CI335 & 4   \\ \hline
CI323 & 5   \\ \hline
CI333, CI324, CI325 & 6   \\ \hline
CI243 & 8   \\ \hline
CI211 & 9   \\ \hline
CI341 & 11  \\ \hline
CI326 & 15  \\ \hline
CI212, CI336 & 17  \\ \hline
CH310 & 21  \\ \hline
CI315 & 22  \\ \hline
CI242 & 30  \\ \hline
CH22  & 31  \\ \hline
CI221 & 32  \\ \hline
CH23  & 34  \\ \hline
CI311 & 44  \\ \hline
CH35  & 54  \\ \hline
CH44  & 95  \\ \hline
CH33  & 105 \\ \hline
CH21  & 123 \\ \hline
CI312 & 159 \\ \hline
CI314 & 206 \\ \hline
CH311, CH312 & 237 \\ \hline
\end{tabular}
\caption{All implemented automatic information privacy risk assessment tool strategies and their found appearance count throughout the static code analysis phase of this thesis.}
\label{table:strategyResults}
\end{table}

% EVALUATION OF THE AUTOMATED INFORMATION PRIVACY RISK ASSESSMENT TOOL
\subsection{Evaluation of the Automated Information Privacy Risk Assessment Tool}

Table \ref{table:reviewerResults} shows the results of the two human reviewer that inspected the source code of the three test-apps for information privacy risks.
For simplification, we will from now on refer to the \aiprat as 'the computer' and the human reviewers as 'the human'.
To compare the results of the human researchers to the automated information privacy risk assessment tool, we add the results that 'the computer' detected to table \ref{table:reviewerResults}.

% TABLE: REVIEWER RESULTS
\begin{table}[h]
\centering
\begin{tabular}{|p{6.6cm}|c|c|c|}
\hline
& \textbf{Computer} & \textbf{Researcher 1} & \textbf{Researcher 2} \\ \hline
siyami.apps.patientregister         & 16                & 21                    & 20                    \\ \hline
medicaljoyworks.prognosis.questions & 13                & 9                     & 10                    \\ \hline
szyk.myheart                        & 14                & 7                     & 11                    \\ \hline
\end{tabular}
\caption{The three human-reviewed apps with the strategy-"found" count results by the automated tool and the two human reviewers.}
\label{table:reviewerResults}
\bigskip
\raggedright{Note: The app package names were shortened by the prefix 'com.' for graphical reasons.}
\end{table}

For the app \textit{com.siyami.apps.patientregister} the human researcher found on average 20.5 information privacy risk, whereas the computer found  16.
The two human researchers were able to detect 9.5 information privacy risks on average for app \linebreak\textit{com.medicaljoyworks.prognosis.questions}.
The computer tool was able to find 13 information privacy risks.
For the app \textit{com.szyk.myheart} the computer was able to detect 14 apps.
The human researchers in comparison did only detect 9 information privacy risks on average.

The full information privacy risk assessment results of apps by the human researchers can be found in the table of Appendix B.

Both researchers reported to have started the \sca by looking at the central \textit{AndroidManifest.xml} file for permissions that the apps claimed.
Permissions would indicate the usage of camera, microphone or location data, for instance.
Another early step was to detect if any background services are being started by the app in question.
Background services are commonly used to implement data synchronization implementations.
