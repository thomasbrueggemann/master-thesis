\section{Discussion}

The following chapter will discuss the results and limitations of this work and provide a possible outlook into future research applications.

\subsection{Principal Findings}

In order the evaluate the degree to which the assessment of information privacy risks for \mH apps can be automated via static code analysis we compared the \ipr found results of the \aiprat with the results from the human researchers.

While it is clear that the computer is faster in processing files and scanning the file's content, the human has at least one advantage over the computer: understanding or estimating context of source code based on his experience.

We were unable to implement a \ml approach to identify all information privacy risks.
Especially difficult is, for instance, the identification of previously unknown analytics or advertisement libraries.
The \ml approach was unfeasible due to the missing context and meta information for the software to learn from.
Using just a line of code to teach the \ml implementation a pattern is not sufficient, since there is no further meta information that could be compared by the algorithm.
Looking at the \ml of \textcite{Shabtai2010}, the problems regarding the context in our approach become clearer.
\textcite{Shabtai2010} used the complete text body of all Java code files within each app to train the \ml classifier to distinguish between two app categories.\footnote{See \cite{Shabtai2010}, p. 330.}
A analytics or advertisement library can be named virtually anything, without any pattern.
Therefore, the computer needs a list of possible analytics and advertisement libraries in order to identify them in a static code analysis.
We used analytics and advertisement libraries as an example of two information privacy risks here, the \ml approach problems apply to other \ipr strategies as well.

The context interpretation skills of humans became even more obvious, during the manual review by the two researchers.
The computer, for instance, did not identify the \ipr 'InformationCollectionTypeContent' $\rightarrow$ 'HealthContent' implemented in strategy \textit{CI343} for the test app 'com.siyami.apps.patientregister' because the matching source code was obfuscated.\footnote{See coherent row for \textit{CI343} of app 'com.siyami.apps.patientregister'  in table of Appendix A.}
The human researchers on the other side were able to identify the 'HealthContent' \textit{CI343} \ipr because they were able to interpret the context in which the obfuscated code was used, by interpreting source code comments for instance or interpreting the screen context.

Another example where the human reviewer is superior to the computer in identifying \ipr with a \sca is the strategy \textit{CI326} 'OwnUniqueIdentifierContent'.
A unique identifier can be implemented in many shapes and it is therefore especially difficult to detect.
A human reviewer has the advantage to interpret variable names and the context that variables are used in to identify a unique user.
A unique user identification can be a randomly generated string, the email address of the user or any other unique feature that is unique to a single user.

Additionally, it is difficult for the computer software to generalise concepts.
The human reviewer can estimate how likely it is, that a higher hierarchy level \ipp bears an \ipr within the current app, but understanding the context.
In order for the computer to decide weather a high-level hierarchy is found, it has to check all the containing sub-hierarchy \ipp first.
The human reviewer has, yet again, the benefit of context interpretation to generalise risk factors.

We have met the first sub-objective, declared in chapter \ref{chapter:Objectives}, by stepping through the \ipp provided by \textcite{Dehling2016} and extracted the \ipp that potentially bear an \ipr to \mH app users.
This progress was documented in chapter \ref{chapter:Relevant}.

We developed strategies for each of the relevant \ipp to be identified within the source code of \mH apps in chapter \ref{sssec:SCAP}, in order to achieve the second sub-objective.

The final and third sub-objective is to compare the results of the human source code review with the results of the \aiprat and highlight the differences in results between human and computer.
The discussion of these results took place in this chapter.

Finally, in order to find a reasonable way to express the degree to what the assessment of information privacy risks can be automated, we will apply the following process.
At first, we identified 55 of the \ipp to be relevant for posing an information privacy risk. 
45 of these \ipp were able to be implemented within the \aiprat and therefore the 'implementation rate' is:
\begin{equation}
	\frac{45}{55}=0.818
\end{equation}

In a second step we will use the results from table \ref{table:reviewerResultsCertainty} to generate an index number that expresses the performance of the computer in relation to the human in assessing information privacy risks.
We argue that the cumulative certainty levels (CCL) express the degree to which  the information privacy risk assessment of \mH apps more accurately than the simple sum of 'found' \ipp for each app.
For every row in table \ref{table:reviewerResultsCertainty}, we are taking the maximum number of the CCL as 100\% and calculate the fraction percentage that the computer found from the 100\%.
We will then take the average value of the just calculated fractions.
This would result in a 'detection rate' of:
\begin{equation}
	\frac{\frac{11.25}{12.75} + \frac{9.25}{9.25} + \frac{9.75}{9.75}}{3} = 0.96
\end{equation}

For the sake of the calculation of this degree value, we will not take the fact that we were only able to decompile and analyze a fraction of the downloaded apps, due to hardware limitations, into account.
We will not lower the degree based on the percentage of apps that was downloadable or able to be analyzed by \textit{FlowDroid}.
These limitations can possibly be eliminated in future research by applying more computation power and time to the analysis.
But, to combine the 'implementation rate' and the 'detection rate', we will take the average of the two values, which results in:

\begin{equation}
	\frac{0.818 + 0.96}{2} = 0.889
\end{equation}

We therefore conclude, that the degree to which an \aiprat is feasible or implementable is 88.9\%.
A completely automated information privacy risk assessment is "desirable but unrealistic today" \footnote{\cite{Knorr2015}, p. 7.}.

\subsection{Contributions}

As a contribution of the results of this thesis, we propose our implementation of an \aiprat that works in a three step process.
The tool downloads, decompiles and analyses an APK file of an app to perform the information privacy risk analysis.

In an attempt to evaluate the outcome of the \aiprat we compared the results of a \sca of two human researchers to the results of the computer.

The contribution of this thesis is the increase of knowledge, that an automated information privacy risk assessment is possible up to a degree of 88.9\%

\subsection{Limitations}\label{chapter:Limitations}

The most effecting limitation during this study was the time constraint.
The time constraint applies to the time we were able to implement the \aiprat as well as the time we were able to run the tool afterwards.
It would be possible to run the analysis for longer and on more apps, with more time available and a budget for computation resources.

Developing such a holistic approach on the identification of the degree a \sca might be usable to identify \ipr within \mH apps automatically resulted in cutting the implementation of the \ipr detecting strategies short, in some cases.
While some \ipr are currently detected by using search words and scanning the source code, it would be ideal to create a tool that automatically learns search words form a training set and applies this knowledge to further app analysis.
In order to develop a machine learning approach on detecting features or patterns in source code files, it is always necessary to have meta information on the source code lines available.
We applied a machine learning approach to classify URLs that are called from within the app into categories. 
We were able to acquire meta information on the URLs (the description HTML text) that allowed the classification algorithm to learn the description text words for each URL and category.
For a Java code line there is no such thing as meta information or even the ability to break a code line into acceptable, 'learnable' features.
In order to identify, for instance, analytics libraries it is not enough to break the source code lines of the analytics library call up, 'learn' the source code line parts and apply the 'knowledge' to further lines.
Analytics libraries, for instance, can be called in many ways and their \acs{API}s are not uniform.
Therefore we were unable to implement more machine learning applications other than the URL classification.

Furthermore, the output of the \aiprat is a rather technical accumulation of the \sca strategy outputs.
The results have not been aggregated into a single information privacy index or a more user friendly communication or interpretation of the information privacy risks detected.

\subsection{Future Research}

Since this study targeted more than one field of interest, future research can target a manifold of improvements.

First of all, the provision of source code files could be improved. 
Currently no access to the binary source code files of other app store provider than the Google Play Store are possible.
Future researchers could organise partnerships with other app store providers to gain legal access to their app source code files.

Another major factor of improvement is the computation power and time that we were able to spend on the decompilation and analysis phase.
Future researchers could use dedicated computers to run the decompilation and analysis phases or even develop this software, or the memory-critical \textit{FlowDroid} toolset, further into a cluster application that runs on multiple machines.
This could allow future researchers, with less of a time-constraint, to run the analysis on more apps and potentially gain additional insights from the results.

We tried to use as many external and comprehensive resources for finding search words, if strategies called for such.
For example the strategy for the information privacy practice hierarchy \textit{CH35} 'SharingWithAnalystContent' uses search words derived from a collection of Android analytics apps.
These search words can be further extended, or, as mentioned in the previous chapter \ref{chapter:Limitations}, extended into a machine learning approach. 
Future research could enhance the current implementation in a way that it proposes and highlights risky parts of the source code to be reviewed by a human additionally.

The approach of this study can also be seen as a first step towards the larger goal of providing transparency to the \ipr of, especially mHealth, apps.
The outcome of the \aiprat could be incorporated into a user interface, similar to the user interface proposed by \textcite{Bruggemann2016}\footnote{See \cite{Bruggemann2016}, p. 1-10.}.
In this context, future research could inspect the implications and the impact such a detailed \ipr analysis has on the users of apps and app stores, in a user study.

We would also like to encourage future researchers to address the implications an integration of automated information privacy risk assessment may have on the app stores and the submitting of apps to the stores for developers.
Future research could analyse what the effects are if an app store, for instance the Google PlayStore, implements an automated \ipr analysis tool that performs a \sca right after a developer submitted an app and transparently communicates the information privacy risks found within the source code.

\subsection{Conclusion}

In the emerging market of \mH apps, the focus on information privacy risks is growing.
Based on the large amount of apps in the app stores and the continuous growth, manual review is infeasible.
Yet, to the best of my knowledge, no study thus far linked the \ipr assessment of \mH apps with automatic \sca approaches.
In this thesis, we intruduced an \aiprat that is, with minimal human configuration, able to download, decompile and analyse Android \mH apps.
The \aiprat (AIPRAT) 

\todo{Conclusion tippen}