\section{Discussion}

The following chapter will discuss the results and limitations of this work and provide a possible outlook into future research applications.

\subsection{Principal Findings}

In order the evaluate the degree to which the assessment of information privacy risks for \mH apps can be automated via static code analysis we compare the \ipr found results of the \aiprat with the results from the human researchers.

While it is clear that the computer is faster in processing files and scanning their contents, the human has at least one advantage over the computer: understanding or estimating context of source code based on his experience.

We were unable to implement a \ml approach to identify all information privacy risks.
Especially difficult is, for instance, the identification of previously unknown analytics or advertisement libraries.
The \ml approach was unfeasible due to the missing context and meta information for the software to learn from.
Using just a line of code to teach the \ml implementation a pattern is not sufficient, since there is no further meta information that could be compared by the algorithm.
Looking at the \ml of \textcite{Shabtai2010}, the problems regarding the context in our approach become clearer.
\textcite{Shabtai2010} used the complete text body of all Java code files within each app to train the \ml classifier to distinguish between two app categories.\footnote{See \cite{Shabtai2010}, p. 330.}
A analytics or advertisement library can be named virtually anything, without any pattern.
Therefore, the computer needs a list of possible analytics and advertisement libraries in order to identify them in a static code analysis.
We used analytics and advertisement libraries as an example of two information privacy risks here, the \ml approach problems apply to other \ipr strategies as well.

The context interpretation skills of humans became even more obvious, during the manual review by the two researchers.
The computer, for instance, did not identify the \ipr 'InformationCollectionTypeContent' $\rightarrow$ 'HealthContent' implemented in strategy \textit{CI343} for the test app 'com.siyami.apps.patientregister' because the matching source code was obfuscated.\footnote{See coherent row for \textit{CI343} of app 'com.siyami.apps.patientregister'  in table of Appendix A.}
The human researchers on the other side were able to identify the 'HealthContent' \textit{CI343} \ipr because they were able to interpret the context in which the obfuscated code was used, by interpreting source code comments for instance or interpreting the screen context.

Another example where the human reviewer is superior to the computer in identifying \ipr with a \sca is the strategy \textit{CI326} 'OwnUniqueIdentifierContent'.
A unique identifier can be implemented in many shapes and it is therefore especially difficult to detect.
A human reviewer has the advantage to interpret variable names and the context that variables are used in to identify a unique user.
A unique user identification can be a randomly generated string, the email address of the user or any other unique feature that is unique to a single user.

\todo{Computer kann nicht h√∂heren Hierarchielevel finden, wobei Mensch das estimaten kann}

We have met the first sub-objective, declared in chapter \ref{chapter:Objectives}, by stepping through the \ipp provided by \textcite{Dehling2016} and extracted the \ipp that potentially bear an \ipr to \mH app users.
This progress was documented in chapter \ref{chapter:Relevant}.

We developed strategies for each of the relevant \ipp to be identified within the source code of \mH apps in chapter \ref{sssec:SCAP}, in order to achieve the second sub-objective.

The final and third sub-objective is to compare the results of the human source code review with the results of the \aiprat and highlight the differences in results between human and computer.
The discussion of these results took place in this chapter.

We therefore conclude on the degree that the assessment of \ipr of \mH apps is doable using a \sca is dependent on....

\todo{Elaborate on the degree!}
...
A completely automated information privacy risk assessment is "desirable but unrealistic today"\footnote{\cite{Knorr2015}, p. 7.}

\subsection{Contributions}

As a contribution of the results of this thesis, we propose to review, especially mHealth, apps in a two step process.
First, the computer should perform an automated \sca assessment of \ipr for a given app.
Second, a human researcher could review the \ipr that the computer was unable to detect, to make sure there are no leftover context interpretations, that the computer was unable to identify.

We have shown within this thesis, that the comp

\subsection{Limitations}\label{chapter:Limitations}

The most effecting limitation during this study was the time constraint.
The time constraint applies to the time we were able to implement the \aiprat as well as the time we were able to run the tool afterwards.
It would be possible to run the analysis for longer and on more apps, with more time available and a budget for computation resources.

Developing such a holistic approach on the identification of the degree a \sca might be usable to identify \ipr within \mH apps automatically resulted in cutting the implementation of the \ipr detecting strategies short, in some cases.
While some \ipr are currently detected by using search words and scanning the source code, it would be ideal to create a tool that automatically learns search words form a training set and applies this knowledge to further app analysis.
In order to develop a machine learning approach on detecting features or patterns in source code files, it is always necessary to have meta information on the source code lines available.
We applied a machine learning approach to classify URLs that are called from within the app into categories. 
We were able to acquire meta information on the URLs (the description HTML text) that allowed the classification algorithm to learn the description text words for each URL and category.
For a Java code line there is no such thing as meta information or even the ability to break a code line into acceptable, 'learnable' features.
In order to identify, for instance, analytics libraries it is not enough to break the source code lines of the analytics library call up, 'learn' the source code line parts and apply the 'knowledge' to further lines.
Analytics libraries, for instance, can be called in many ways and their \acs{API}s are not uniform.
Therefore we were unable to implement more machine learning applications other than the URL classification.

Furthermore, the output of the \aiprat is a rather technical accumulation of the \sca strategy outputs.
The results have not been aggregated into a single information privacy index or a more user friendly communication or interpretation of the information privacy risks detected.

\subsection{Future Research}

Since this study targeted more than one field of interest, future research can target a manifold of improvements.

First of all, the provision of source code files could be improved. 
Currently no access to the binary source code files of other app store provider than the Google Play Store are possible.
Future researchers could organise partnerships with other app store providers to gain legal access to their app source code files.

Another major factor of improvement is the computation power and time that we were able to spend on the decompilation and analysis phase.
Future researchers could use dedicated computers to run the decompilation and analysis phases or even develop this software, or the memory-critical \textit{FlowDroid} toolset, further into a cluster application that runs on multiple machines.
This could allow future researchers, with less of a time-constraint, to run the analysis on more apps and potentially gain additional insights from the results.

We tried to use as many external and comprehensive resources for finding search words, if strategies called for such.
For example the strategy for the information privacy practice hierarchy \textit{CH35} 'SharingWithAnalystContent' uses search words derived from a collection of Android analytics apps.
These search words can be further extended, or, as mentioned in the previous chapter \ref{chapter:Limitations}, extended into a machine learning approach. 
Future research could enhance the current implementation in a way that it proposes and highlights risky parts of the source code to be reviewed by a human additionally.

The approach of this study can also be seen as a first step towards the larger goal of providing transparency to the \ipr of, especially mHealth, apps.
The outcome of the \aiprat could be incorporated into a user interface, similar to the user interface proposed by \textcite{Bruggemann2016}\footnote{See \cite{Bruggemann2016}, p. 1-10.}.
In this context, future research could inspect the implications and the impact such a detailed \ipr analysis has on the users of apps and app stores, in a user study.

We would also like to encourage future researchers to address the implications an integration of automated information privacy risk assessment may have on the app stores and the submitting of apps to the stores for developers.
Future research could analyse what the effects are if an app store, for instance the Google PlayStore, implements an automated \ipr analysis tool that performs a \sca right after a developer submitted an app and transparently communicates the information privacy risks found within the source code.


\subsection{Conclusion}